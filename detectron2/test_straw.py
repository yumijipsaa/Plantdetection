import os
import json
import torch
from detectron2.config import get_cfg
from detectron2.engine import DefaultPredictor
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog

# ğŸ”¹ ë°ì´í„°ì…‹ ì •ë³´
dataset_name = "straw_test"
json_path = "D:/plantdetection/detectron2/data/straw_test/dataset.json"
image_root = "D:/plantdetection/detectron2"  
output_folder = "D:/plantdetection/detectron2/inference_result/"

# ğŸ”¹ ì¶œë ¥ í´ë” ìƒì„±
os.makedirs(output_folder, exist_ok=True)

# ğŸ”¹ COCO ë°ì´í„°ì…‹ ë“±ë¡
register_coco_instances(dataset_name, {}, json_path, image_root)


# class_names = ['flower', 'fruit', 'cap', 'leaf', 'midrib', 'stem', 'node', 'cap_2']

# ğŸ”¹ ëª¨ë¸ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
cfg = get_cfg()
cfg.merge_from_file("model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")


cfg.MODEL.WEIGHTS = "2024-05-20_1419_strawberry_208749.pth"  # í•™ìŠµëœ ê°€ì¤‘ì¹˜
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6  # í´ë˜ìŠ¤ ê°œìˆ˜ ê³ ì •
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1  # ì‹ ë¢°ë„ ì„ê³„ê°’
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"  # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU ì‚¬ìš©



# # ğŸ”¹ ëª¨ë¸ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
# cfg = get_cfg()
# cfg.merge_from_file("model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
# cfg.MODEL.WEIGHTS = "2024-04-16_1039_paprika_658000.pth"  # í•™ìŠµëœ ê°€ì¤‘ì¹˜
# cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_names)
# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1  # ì‹ ë¢°ë„ ì„ê³„ê°’ ë‚®ì¶°ì„œ ë¶„ì„
# cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ğŸ”¹ Windows multiprocessing ë¬¸ì œ ë°©ì§€
if __name__ == '__main__':
    # ğŸ”¹ mAP í‰ê°€
    evaluator = COCOEvaluator(dataset_name, cfg, False, output_dir=output_folder)
    val_loader = build_detection_test_loader(cfg, dataset_name, num_workers=0)
    model = DefaultPredictor(cfg).model

    print("ğŸ” í‰ê°€ ì¤‘...")
    metrics = inference_on_dataset(model, val_loader, evaluator)

    # ğŸ”¹ mAP ê²°ê³¼ ì €ì¥
    map_result_path = os.path.join(output_folder, "map_results.json")
    with open(map_result_path, "w") as f:
        json.dump(metrics, f, indent=4)

    print(f"\nâœ… mAP ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {map_result_path}")
    print(f"ğŸ“Š mAP ê²°ê³¼: {metrics}")
